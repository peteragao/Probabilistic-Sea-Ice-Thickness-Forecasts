<!--HOW TO COMPLETE THIS FORM:-->

<!--
1. Checkboxes in this document appear as follows: 

- [ ] This is a checkbox 

To check a checkbox, replace [ ] by [x], as follows: 

- [x] This is a checked checkbox 

Note that current versions of RStudio for Mac (this will change with RStudio versions 1.3 and higher) will not create a formatted checkbox but will leave the original characters, i.e., literally "[ ]" or "[x]". It's fine to submit a PDF in this form.
 
2. For text answers, simply type the relevant text in the areas indicated. A blank line starts a new paragraph. 
 
3. Comments (like these instructions) provide additional instructions throughout the form. There is no need to remove them; they will not appear in the compiled document. 

4. If you are comfortable with Markdown syntax, you may choose to include any Markdown-compliant formatting in the form. For example, you may wish to include R code chunks and compile this document in R Markdown.
-->

This form documents the artifacts associated with the article (i.e., the data and code supporting the computational findings) and describes how to reproduce the findings.


# Part 1: Data

- [ ] This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code).

<!--
If box above is checked and if no simulated/synthetic data files are provided by the authors, please skip directly to the Code section. Otherwise, continue.
-->

- [x] I certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.

<!-- If data are simulated using random number generation, please be sure to set the random number seed in the code you provide -->

## Abstract

<!--
Provide a short (< 100 words), high-level description of the data
-->

The contour model forecasts are based on sea ice concentration estimates from the National Aeronautics and Space Administration Nimbus-7 SMMR and DMSP SSM/I-SSMIS satellites and the conditional thickness forecasts are based on sea ice thickness estimates produced via the Alfred Wegener Institute Climate Model (AWI-CM. We evaluate our forecasts via comparison with ensembles of dynamical forecasts produced by the European Centre for Medium-Range Weather Forecasts (ECMWF). We also refer to maps and grids produced by thee National Snow and Ice Data Center.

## Availability


- [x] Data **are** publicly available.
- [ ] Data **cannot be made** publicly available.

If the data are publicly available, see the *Publicly available data* section. Otherwise, see the *Non-publicly available data* section, below.

### Publicly available data

- [x] Data are available online at:

    - The sea ice concentration data and associated grid information can be accessed at [the NSIDC website](https://nsidc.org/data/nsidc-0051).
    
    - The sea ice thickness estimates and associated grid information can be accessed at [Zenodo](https://zenodo.org/record/3597428) in the Exp_CTD_T_SIC_SIT_SIV.tar.bz file.
    
    - The NSIDC region definitions can be accessed at [the NSIDC website](https://nsidc.org/data/polar-stereo/tools_masks.html).

- [ ] Data are available as part of the paperâ€™s supplementary material.

- [x] Data are publicly available by request, following the process described here:

    - The ECMWF forecasts can be obtained by submitting a request to the [Climate Data Store](https://cds.climate.copernicus.eu/contact-us).


- [ ] Data are or will be made available through some other mechanism, described here:


<!-- If data are available by request to the authors or some other data owner, please make sure to explain the process of requesting access to the data. -->

### Non-publicly available data

<!--
The Journal of the American Statistical Association requires authors to make data accompanying their papers available to the scientific community except in cases where: 1) public sharing of data would be impossible, 2) suitable synthetic data are provided which allow the main analyses to be replicated (recognizing that results may differ from the "real" data analyses), and 3) the scientific value of the results and methods outweigh the lack of reproducibility.

Please discuss the lack of publicly available data. For example:
-	why data sharing is not possible,
-	what synthetic data are provided, and 
-	why the value of the paper's scientific contribution outweighs the lack of reproducibility.
-->

## Description

### File format(s)

<!--
Check all that apply
-->
- [ ] CSV or other plain text.
- [ ] Software-specific binary format (.Rda, Python pickle, etc.): pkcle
- [x] Standardized binary format (e.g., netCDF, HDF5, etc.): 
- [ ] Other (please specify):

### Data dictionary

<!--
A data dictionary provides information that allows users to understand the meaning, format, and use of the data.
-->

- [ ] Provided by authors in the following file(s):
- [ ] Data file(s) is(are) self-describing (e.g., netCDF files)
- [x] Available at the following URL: 

    - The sea ice concentration data and associated grid information are described at [the NSIDC website](https://nsidc.org/data/nsidc-0051).
    
    - The sea ice thickness estimates and associated grid information are described at [Zenodo](https://zenodo.org/record/3597428).
    
    - The NSIDC region definitions are described at [the NSIDC website](https://nsidc.org/data/polar-stereo/tools_masks.html).

### Additional Information (optional)

<!-- 
OPTIONAL: Provide any additional details that would be helpful in understanding the data. If relevant, please provide unique identifier/DOI/version information and/or license/terms of use.
-->

The sea ice thickness estimates are associated with the DOI [10.5281/zenodo.3597427](https://doi.org/10.5281/zenodo.3597427).

# Part 2: Code

## Abstract

<!--
Provide a short (< 100 words), high-level description of the code. If necessary, more details can be provided in files that accompany the code.
-->

We provide code to reproduce the results in the manuscript. In particular, we provide R scripts for cleaning the data, fitting the contour model and generating contour forecasts, fitting the conditional thickness model and generating thickness forecasts, and summarizing results and generating figures. In practice, the code for fitting the conditional thickness model was run on multiple machines.

## Description

The main script which outlines the steps for reproducing our analysis is `R/main.R`. Helper scripts are stored in `R/`, data should be saved to `data/`, and output and results are saved by default to `output/`.

### Code format(s)

<!--
Check all that apply
-->
- [x] Script files
    - [x] R
    - [ ] Python
    - [ ] Matlab
    - [ ] Other: 
- [ ] Package
    - [ ] R
    - [ ] Python
    - [ ] MATLAB toolbox
    - [ ] Other: 
- [ ] Reproducible report 
    - [ ] R Markdown
    - [ ] Jupyter notebook
    - [ ] Other:
- [ ] Shell script
- [ ] Other (please specify): 

### Supporting software requirements

#### Version of primary software used

<!--
(e.g., R version 3.6.0)
-->
R version 3.5.1

#### Libraries and dependencies used by the code

<!--
Include version numbers (e.g., version numbers for any R or Python packages used)
-->

abind 1.4.5, akima 0.6.2, base 3.5.1, datasets 3.5.1, dplyr 0.8.3, ggplot2 3.3.0, graphics 3.5.1, grDevices 3.5.1, gstat 2.0.3, IceCast 2.1.0, INLA 19.4.9, latex2exp 0.4.0, lattice 0.20.38, latticeExtra 0.6.28, lubridate 1.7.4, maptools 1.0.1, Matrix 1.2.17, methods 3.5.1, ncdf4 1.17, parallel 3.5.1, proj4 1.0.10, raster 3.1.5, rasterVis 0.46, RColorBrewer 1.1.2, rgeos 0.5.3, sf 0.8.0, sp 1.4.1, spheRlab 1.1.5, stars 0.3.1, stats 3.5.1, stringr 1.4.0, tidyr 1.0.0, utils 3.5.1, viridis 0.5.1, viridisLite 0.3.0, xtable 1.8.4

### Supporting system/hardware requirements (optional)

<!--
OPTIONAL: System/hardware requirements including operating system with version number, access to cluster, GPUs, etc.
-->

Code for summarizing results, and generating plots was run on a 2017 MacBook Pro (Mojave 10.14.6, 2.3 GHz Intel Core i5, 16 GB 2133 MHz LPDDR3). Code for cleaning the data and the contour and conditional thickness models were run on a cluster of multiple machines running Debian 8. 

### Parallelization used

- [ ] No parallel code used
- [ ] Multi-core parallelization on a single machine/node
    - Number of cores used: 
- [X] Multi-machine/multi-node parallelization 
    - Number of nodes and cores used: 3 nodes, 243 cores

### License

- [x] MIT License (default)
- [ ] BSD 
- [ ] GPL v3.0
- [ ] Creative Commons
- [ ] Other: (please specify below)


### Additional information (optional)

<!--
OPTIONAL: By default, submitted code will be published on the JASA GitHub repository (http://github.com/JASA-ACS) as well as in the supplementary material. Authors are encouraged to also make their code available in a public repository. If relevant, please provide unique identifier/DOI/version information.

# Part 3: Reproducibility workflow

<!--
The materials provided should provide a straightforward way for reviewers and readers to reproduce analyses with as few steps as possible. 
-->

For each initialization month, we fit and generated forecasts from the conditional thickness model using a single cluster node and core.

## Scope

The provided workflow reproduces:

- [x] Any numbers provided in text in the paper
- [x] All tables and figures in the paper
- [ ] Selected tables and figures in the paper, as explained and justified below:

## Workflow

To produce our results, we first obtained from the above sources and saved in `data/`. Next, as outlined in the file `R/main.R`, we call several helper scripts to load and clean data, fit models and generate forecasts, and finally summarize and evaluate our results. Final tables and figures used in the manuscript are stored in `output/paper/`.

### Format(s)

<!--
Check all that apply
-->
- [x] Single master code file 
- [ ] Wrapper (shell) script(s)
- [ ] Self-contained R Markdown file, Jupyter notebook, or other literate programming approach
- [ ] Text file (e.g., a readme-style file) that documents workflow
- [ ] Makefile
- [ ] Other (more detail in *Instructions* below)

### Instructions

<!--
Describe how to use the materials provided to reproduce analyses in the manuscript. Additional details can be provided in file(s) accompanying the reproducibility materials.
-->

The main script `R/main.R` provides the order for running the scripts. The file `R/00_cleaning/clean_data.R` provides information on required inputs and expected output files involved in data cleaning and processing. Data files can be obtained from the above sources and saved in the folders `data/raw_ECMWF/`, `data/raw_AWI_CM/`, `data/raw_NSIDC/`, and `data/bootstrapV3_1/`. Next, the contour model can be fit by running `R/01_contour/get_contour_forecasts.R` and the conditional thickness model can be fit by running `R/02_cdn_thickness/get_thickness_forecasts.R`. Finally, we summarize our results and generate tables and figures using the scripts `R/03_evaluation/summarize_results.R` and  `R/03_evaluation/make_paper_figures.R`.

### Expected run-time

Approximate time needed to reproduce the analyses on a standard desktop machine:

- [ ] < 1 minute
- [ ] 1-10 minutes
- [ ] 10-60 minutes
- [ ] 1-8 hours
- [ ] > 8 hours
- [x] Not feasible to run on a desktop machine, as described here:

Code for cleaning the AWI-CM, NSIDC, and NASA data can be run on a desktop machine in approximately four hours. The ECMWF data is substantial (~150GB), so we ran code for summarizing and cleaning the ECMWF data in about 6 hours  using one core of a single cluster node. For each initialization month, fitting the contour model and conditional thickness model take about one day using one core of a single cluster node, requiring 80GB of RAM. Code for summarizing results and generating plots can be run on a desktop machine in about one hour.
 
### Additional information (optional)

<!--
OPTIONAL: Additional documentation provided (e.g., R package vignettes, demos or other examples) that show how to use the provided code/software in other settings.
-->

# Notes (optional)

<!--
OPTIONAL: Any other relevant information not covered on this form. If reproducibility materials are not publicly available at the time of submission, please provide information here on how the reviewers can view the materials.
-->
